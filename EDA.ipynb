{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Traffic Light Dataset - Exploratory Data Analysis\n",
        "\n",
        "This notebook analyzes the training dataset structure, which contains 13 different video sequences (dayClip1-13), each with sequential frames of traffic light images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "\n",
        "# Set visualization style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Dataset path\n",
        "DATA_ROOT = \"/Users/jeremyky/Documents/ae/training_dataset\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset Structure Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get all dayClip directories\n",
        "clip_dirs = sorted([d for d in Path(DATA_ROOT).iterdir() if d.is_dir() and d.name.startswith('dayClip')])\n",
        "\n",
        "print(f\"Total number of video sequences (clips): {len(clip_dirs)}\\n\")\n",
        "\n",
        "# Collect information about each clip\n",
        "clip_info = []\n",
        "\n",
        "for clip_dir in clip_dirs:\n",
        "    frames_dir = clip_dir / \"frames\"\n",
        "    if frames_dir.exists():\n",
        "        # Get all jpg files\n",
        "        frames = sorted(glob(str(frames_dir / \"*.jpg\")))\n",
        "        clip_info.append({\n",
        "            'Clip Name': clip_dir.name,\n",
        "            'Number of Frames': len(frames),\n",
        "            'Frames Directory': str(frames_dir)\n",
        "        })\n",
        "\n",
        "# Create a DataFrame\n",
        "df_clips = pd.DataFrame(clip_info)\n",
        "print(df_clips.to_string(index=False))\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"TOTAL FRAMES ACROSS ALL CLIPS: {df_clips['Number of Frames'].sum():,}\")\n",
        "print(f\"Average frames per clip: {df_clips['Number of Frames'].mean():.1f}\")\n",
        "print(f\"Median frames per clip: {df_clips['Number of Frames'].median():.1f}\")\n",
        "print(f\"Min frames in a clip: {df_clips['Number of Frames'].min()}\")\n",
        "print(f\"Max frames in a clip: {df_clips['Number of Frames'].max()}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Distribution of Frames Across Clips\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Bar plot\n",
        "axes[0].bar(df_clips['Clip Name'], df_clips['Number of Frames'], color='steelblue', alpha=0.7)\n",
        "axes[0].set_xlabel('Clip Name', fontsize=12)\n",
        "axes[0].set_ylabel('Number of Frames', fontsize=12)\n",
        "axes[0].set_title('Number of Frames per Clip', fontsize=14, fontweight='bold')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, v in enumerate(df_clips['Number of Frames']):\n",
        "    axes[0].text(i, v + 50, str(v), ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# Pie chart showing proportion\n",
        "axes[1].pie(df_clips['Number of Frames'], labels=df_clips['Clip Name'], autopct='%1.1f%%', startangle=90)\n",
        "axes[1].set_title('Proportion of Total Frames per Clip', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Sample Images from Each Clip\n",
        "\n",
        "Let's visualize the first frame from each clip to get a sense of the data variety.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display first frame from each clip\n",
        "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, clip_dir in enumerate(clip_dirs):\n",
        "    frames_dir = clip_dir / \"frames\"\n",
        "    frames = sorted(glob(str(frames_dir / \"*.jpg\")))\n",
        "    \n",
        "    if frames:\n",
        "        # Load first frame\n",
        "        img = Image.open(frames[0])\n",
        "        axes[idx].imshow(img)\n",
        "        axes[idx].set_title(f\"{clip_dir.name}\\n({len(frames)} frames)\", fontsize=10, fontweight='bold')\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "# Hide the last subplot if we have fewer than 16 clips\n",
        "for idx in range(len(clip_dirs), len(axes)):\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.suptitle('First Frame from Each Video Clip', fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Image Properties Analysis\n",
        "\n",
        "Analyze dimensions, file sizes, and color properties of the images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample images from each clip for analysis\n",
        "image_properties = []\n",
        "\n",
        "for clip_dir in clip_dirs:\n",
        "    frames_dir = clip_dir / \"frames\"\n",
        "    frames = sorted(glob(str(frames_dir / \"*.jpg\")))\n",
        "    \n",
        "    # Sample up to 10 frames from each clip for analysis\n",
        "    sample_size = min(10, len(frames))\n",
        "    sampled_frames = np.random.choice(frames, sample_size, replace=False)\n",
        "    \n",
        "    for frame_path in sampled_frames:\n",
        "        img = Image.open(frame_path)\n",
        "        file_size_kb = os.path.getsize(frame_path) / 1024\n",
        "        \n",
        "        image_properties.append({\n",
        "            'Clip': clip_dir.name,\n",
        "            'Width': img.width,\n",
        "            'Height': img.height,\n",
        "            'Mode': img.mode,\n",
        "            'File Size (KB)': file_size_kb\n",
        "        })\n",
        "\n",
        "df_props = pd.DataFrame(image_properties)\n",
        "\n",
        "print(\"Image Properties Summary:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total images sampled: {len(df_props)}\")\n",
        "print(f\"\\nDimensions:\")\n",
        "print(f\"  Width: {df_props['Width'].unique()}\")\n",
        "print(f\"  Height: {df_props['Height'].unique()}\")\n",
        "print(f\"  Image Mode: {df_props['Mode'].unique()}\")\n",
        "print(f\"\\nFile Sizes:\")\n",
        "print(f\"  Average: {df_props['File Size (KB)'].mean():.2f} KB\")\n",
        "print(f\"  Min: {df_props['File Size (KB)'].min():.2f} KB\")\n",
        "print(f\"  Max: {df_props['File Size (KB)'].max():.2f} KB\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Sequential Frame Visualization\n",
        "\n",
        "Visualize a sequence of frames from one clip to see the temporal progression.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pick a clip with many frames for sequential visualization\n",
        "clip_to_visualize = clip_dirs[0]  # Change index to visualize different clips\n",
        "frames_dir = clip_to_visualize / \"frames\"\n",
        "frames = sorted(glob(str(frames_dir / \"*.jpg\")))\n",
        "\n",
        "# Select evenly spaced frames\n",
        "num_frames_to_show = 12\n",
        "indices = np.linspace(0, len(frames)-1, num_frames_to_show, dtype=int)\n",
        "\n",
        "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, idx in enumerate(indices):\n",
        "    img = Image.open(frames[idx])\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].set_title(f\"Frame {idx} / {len(frames)-1}\", fontsize=10)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle(f'Sequential Frames from {clip_to_visualize.name}', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Color Distribution Analysis\n",
        "\n",
        "Analyze the RGB color distributions across sample images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample random images from across all clips\n",
        "all_frames = []\n",
        "for clip_dir in clip_dirs:\n",
        "    frames_dir = clip_dir / \"frames\"\n",
        "    frames = glob(str(frames_dir / \"*.jpg\"))\n",
        "    all_frames.extend(frames)\n",
        "\n",
        "# Randomly sample images for color analysis\n",
        "sample_images = np.random.choice(all_frames, min(100, len(all_frames)), replace=False)\n",
        "\n",
        "# Collect RGB statistics\n",
        "r_values, g_values, b_values = [], [], []\n",
        "\n",
        "for img_path in sample_images:\n",
        "    img = np.array(Image.open(img_path))\n",
        "    r_values.extend(img[:,:,0].flatten()[::100])  # Sample every 100th pixel to reduce memory\n",
        "    g_values.extend(img[:,:,1].flatten()[::100])\n",
        "    b_values.extend(img[:,:,2].flatten()[::100])\n",
        "\n",
        "# Plot histograms\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "axes[0].hist(r_values, bins=50, color='red', alpha=0.7, edgecolor='black')\n",
        "axes[0].set_title('Red Channel Distribution', fontweight='bold')\n",
        "axes[0].set_xlabel('Pixel Value')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "\n",
        "axes[1].hist(g_values, bins=50, color='green', alpha=0.7, edgecolor='black')\n",
        "axes[1].set_title('Green Channel Distribution', fontweight='bold')\n",
        "axes[1].set_xlabel('Pixel Value')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "\n",
        "axes[2].hist(b_values, bins=50, color='blue', alpha=0.7, edgecolor='black')\n",
        "axes[2].set_title('Blue Channel Distribution', fontweight='bold')\n",
        "axes[2].set_xlabel('Pixel Value')\n",
        "axes[2].set_ylabel('Frequency')\n",
        "\n",
        "plt.suptitle('RGB Channel Distributions (Sampled Pixels)', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Color Statistics (sampled from {len(sample_images)} images):\")\n",
        "print(f\"Red   - Mean: {np.mean(r_values):.2f}, Std: {np.std(r_values):.2f}\")\n",
        "print(f\"Green - Mean: {np.mean(g_values):.2f}, Std: {np.std(g_values):.2f}\")\n",
        "print(f\"Blue  - Mean: {np.mean(b_values):.2f}, Std: {np.std(b_values):.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Average Image per Clip\n",
        "\n",
        "Create an \"average frame\" for each clip to see the overall composition.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute average image for each clip (using a sample of frames)\n",
        "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, clip_dir in enumerate(clip_dirs):\n",
        "    frames_dir = clip_dir / \"frames\"\n",
        "    frames = sorted(glob(str(frames_dir / \"*.jpg\")))\n",
        "    \n",
        "    # Sample frames to average (max 50 to avoid memory issues)\n",
        "    sample_size = min(50, len(frames))\n",
        "    sampled = np.random.choice(frames, sample_size, replace=False)\n",
        "    \n",
        "    # Load and average\n",
        "    images = [np.array(Image.open(f)) for f in sampled]\n",
        "    avg_img = np.mean(images, axis=0).astype(np.uint8)\n",
        "    \n",
        "    axes[idx].imshow(avg_img)\n",
        "    axes[idx].set_title(f\"{clip_dir.name}\\n(avg of {sample_size} frames)\", fontsize=10, fontweight='bold')\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "# Hide unused subplots\n",
        "for idx in range(len(clip_dirs), len(axes)):\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.suptitle('Average Image per Clip', fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Dataset Summary & Recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"DATASET SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nTotal Video Sequences: {len(clip_dirs)}\")\n",
        "print(f\"Total Frames: {df_clips['Number of Frames'].sum():,}\")\n",
        "print(f\"\\nFrame Distribution:\")\n",
        "print(f\"  - Shortest clip: {df_clips.loc[df_clips['Number of Frames'].idxmin(), 'Clip Name']} \"\n",
        "      f\"({df_clips['Number of Frames'].min()} frames)\")\n",
        "print(f\"  - Longest clip: {df_clips.loc[df_clips['Number of Frames'].idxmax(), 'Clip Name']} \"\n",
        "      f\"({df_clips['Number of Frames'].max()} frames)\")\n",
        "print(f\"  - Average: {df_clips['Number of Frames'].mean():.1f} frames per clip\")\n",
        "\n",
        "print(f\"\\nImage Properties:\")\n",
        "print(f\"  - Dimensions: {df_props['Width'].iloc[0]} × {df_props['Height'].iloc[0]} pixels\")\n",
        "print(f\"  - Color Mode: {df_props['Mode'].iloc[0]}\")\n",
        "print(f\"  - Average File Size: {df_props['File Size (KB)'].mean():.2f} KB\")\n",
        "\n",
        "total_size_mb = (df_clips['Number of Frames'].sum() * df_props['File Size (KB)'].mean()) / 1024\n",
        "print(f\"\\nEstimated Total Dataset Size: {total_size_mb:.2f} MB\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"RECOMMENDATIONS FOR TRAINING\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "1. Data Imbalance: Some clips have significantly more frames than others.\n",
        "   Consider stratified sampling or weighting during training.\n",
        "\n",
        "2. Image Resize: Current images may need resizing to 256×256 for your model.\n",
        "   Verify dimensions match expected input size.\n",
        "\n",
        "3. Temporal Information: Since these are sequential frames, you could:\n",
        "   - Use data augmentation (but avoid breaking temporal consistency)\n",
        "   - Consider frame sampling strategies (every Nth frame)\n",
        "   - Explore temporal models if needed\n",
        "\n",
        "4. Train/Val Split: Consider splitting by CLIP rather than by individual frames\n",
        "   to avoid data leakage (consecutive frames are very similar).\n",
        "\n",
        "5. Data Augmentation: Be careful with augmentations that might change\n",
        "   traffic light meaning (e.g., color jittering could be problematic).\n",
        "\"\"\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ae_hw2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
